/* The MIT License (MIT)
 *
 * Copyright (c) 2014-2018 David Medina and Tim Warburton
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 */


dfloat __shfl_up   (dfloat var, unsigned int delta, int width=warpSize);
dfloat __shfl_down (dfloat var, unsigned int delta, int width=warpSize);

#define MASK 0xffffffff

#define p_SIMD 32
#define p_NWARPS (SCAN_BLOCK_SIZE/p_SIMD)

@kernel void blockShflScan(dlong N, entry_t *o_a, scan_t *o_scana, scan_t *o_offsets){

  for(dlong b=0;b<(N+SCAN_BLOCK_SIZE-1)/SCAN_BLOCK_SIZE;++b;@outer(0)){

    @shared scan_t s_offsets[p_NWARPS];
    @exclusive scan_t x;
    @exclusive int l, w;
    @exclusive dlong n;
    
    for(int t=0;t<SCAN_BLOCK_SIZE;++t;@inner(0)){
  
      // find lane
      l = t%p_SIMD;
      
      // find warp
      w = t >> 5; // divides by 32
      
      // construct map from thread and thread-block indices into linear array index
      n = t + b*SCAN_BLOCK_SIZE;

      dlong n1 = (n>0) ? n-1:0;

      // load entry and store val
      entry_t an = o_a[n];

      // assume map to integer depends on entry n and n-1
      x = entryMap(an,o_a[n1]); 
      
      // warp based scan using shfl op
      scan_t y;
#if USE_CUDA==1
      y = __shfl_up_sync(MASK, x,  1, p_SIMD); x += (l>= 1) ? y : 0;
      y = __shfl_up_sync(MASK, x,  2, p_SIMD); x += (l>= 2) ? y : 0;
      y = __shfl_up_sync(MASK, x,  4, p_SIMD); x += (l>= 4) ? y : 0;
      y = __shfl_up_sync(MASK, x,  8, p_SIMD); x += (l>= 8) ? y : 0;
      y = __shfl_up_sync(MASK, x, 16, p_SIMD); x += (l>=16) ? y : 0;
#else
      y = __shfl_up(x,  1, p_SIMD); x += (l>= 1) ? y : 0;
      y = __shfl_up(x,  2, p_SIMD); x += (l>= 2) ? y : 0;
      y = __shfl_up(x,  4, p_SIMD); x += (l>= 4) ? y : 0;
      y = __shfl_up(x,  8, p_SIMD); x += (l>= 8) ? y : 0;
      y = __shfl_up(x, 16, p_SIMD); x += (l>=16) ? y : 0;

#endif
      // collect warp offsets
      if(l==31) s_offsets[w] = x;
    }

    @barrier("local"); // ensure all warps have contributed offset
    
    for(int t=0;t<SCAN_BLOCK_SIZE;++t;@inner(0)){
      
      // nominate warp 0 to scan offsets
      if(w==0){
	scan_t offx = s_offsets[l];
	scan_t y;

#if USE_CUDA==1
	y = __shfl_up_sync(MASK, offx,  1, p_SIMD); offx += (l>= 1) ? y : 0;
	y = __shfl_up_sync(MASK, offx,  2, p_SIMD); offx += (l>= 2) ? y : 0;
	y = __shfl_up_sync(MASK, offx,  4, p_SIMD); offx += (l>= 4) ? y : 0;
	y = __shfl_up_sync(MASK, offx,  8, p_SIMD); offx += (l>= 8) ? y : 0;
	y = __shfl_up_sync(MASK, offx, 16, p_SIMD); offx += (l>=16) ? y : 0;
#else
	y = __shfl_up(offx,  1, p_SIMD); offx += (l>= 1) ? y : 0;
	y = __shfl_up(offx,  2, p_SIMD); offx += (l>= 2) ? y : 0;
	y = __shfl_up(offx,  4, p_SIMD); offx += (l>= 4) ? y : 0;
	y = __shfl_up(offx,  8, p_SIMD); offx += (l>= 8) ? y : 0;
	y = __shfl_up(offx, 16, p_SIMD); offx += (l>=16) ? y : 0;

#endif
	s_offsets[l] = offx;
      }
    }

    @barrier("local"); // ensure all warps have contributed offset
    
    for(int t=0;t<SCAN_BLOCK_SIZE;++t;@inner(0)){
      
      // shift by warp offset
      x += (w!=0) ? s_offsets[w-1]:0;
      
      if(n<N)
	o_scana[n] = x;
      
      if(t==SCAN_BLOCK_SIZE-1)
	o_offsets[b] = x;
    }
  }
}




@kernel void finalizeScan(dlong N, scan_t *o_offsets, scan_t *o_scana){

  for(dlong b=0;b<(N+SCAN_BLOCK_SIZE-1)/SCAN_BLOCK_SIZE;++b;@outer(0)){

    for(int t=0;t<SCAN_BLOCK_SIZE;++t;@inner(0)){
      // construct map from thread and thread-block indices into linear array index
      dlong n = t + b*SCAN_BLOCK_SIZE;
      
      if(b>0)
	o_scana[n] += o_offsets[b-1];
    }
  }
}


@kernel void findStarts(dlong N, dlong Nstarts, scan_t *o_scan, scan_t *o_starts){

  for(int n=0;n<N;++n;@tile(256, @outer,@inner)){

    if(n==0)
      o_starts[n] = 0;
    else{
      dlong id = o_scan[n];
      if(id!=o_scan[n-1]) // rely on l1
	o_starts[id] = n;
      if(n==N-1)
	o_starts[Nstarts] = N;
    }
  }


}

@kernel void segmentedReduction_orig(dlong N, dlong Nstarts, scan_t *o_starts, entry_t *o_list, entry_t *o_compactedList){

  for(dlong s=0;s<Nstarts;++s;@outer(0)){

    for(int t=0;t<p_SIMD;++t;@inner(0)){

      dlong id0 = o_starts[s];
      dlong id1 = o_starts[s+1];
      
      dlong n = id0 + t;

      // assume 1 val (sorry)
      dfloat val = 0;
      while(n<id1){
	val += o_list[n].val; // nasty striding
	n+=p_SIMD;
      }

      dfloat y;

#if USE_CUDA==1
      y = __shfl_down_sync(MASK, val,  16, p_SIMD); val += (t<16) ? y : 0;
      y = __shfl_down_sync(MASK, val,   8, p_SIMD); val += (t< 8) ? y : 0;
      y = __shfl_down_sync(MASK, val,   4, p_SIMD); val += (t< 4) ? y : 0;
      y = __shfl_down_sync(MASK, val,   2, p_SIMD); val += (t< 2) ? y : 0;
      y = __shfl_down_sync(MASK, val,   1, p_SIMD); val += (t< 1) ? y : 0;
#else
      y = __shfl_down(val,  16, p_SIMD); val += (t<16) ? y : 0;
      y = __shfl_down(val,   8, p_SIMD); val += (t< 8) ? y : 0;
      y = __shfl_down(val,   4, p_SIMD); val += (t< 4) ? y : 0;
      y = __shfl_down(val,   2, p_SIMD); val += (t< 2) ? y : 0;
      y = __shfl_down(val,   1, p_SIMD); val += (t< 1) ? y : 0;
#endif
      
      if(t==0){
	entry_t acc = o_list[id0]; // should be in l1 (recovers nasty striding  a bit)
	acc.val = val;
	o_compactedList[s] = acc;
      }
    }
  }

}


//#define segmentedReduction_naive segmentedReduction
#define segmentedReduction_segred segmentedReduction
@kernel void segmentedReduction_naive(dlong N, dlong Nstarts, scan_t *o_starts, entry_t *o_list, entry_t *o_compactedList){

  for(dlong s=0;s<Nstarts;++s;@tile(1024,@outer,@inner)){

    dlong id0 = o_starts[s];
    dlong id1 = o_starts[s+1];

    entry_t acc = o_list[id0]; // should be in l1 (recovers nasty striding  a bit)

    for(dlong n=id0+1;n<id1;++n){
      acc.val += o_list[n].val; // nasty striding
    }

    o_compactedList[s] = acc;
  }
  
}


#define mymin(a,b) ( ((a)<(b)) ? (a):(b) )
#define mymax(a,b) ( ((a)>(b)) ? (a):(b) )

@kernel void segmentedReduction_segred(dlong N, dlong Nstarts, scan_t *o_starts, entry_t *o_list, entry_t *o_compactedList){

#define p_NT 32

  for(int b=0;b<(Nstarts+p_NT-1)/p_NT;++b;@outer(0)){

    @shared dfloat s_vals[p_NT];
    
    for(int t=0;t<p_NT;++t;@inner(0)){

      // data range for NT outputs 
      dlong bstart = o_starts[b*p_NT];
      dlong bend   = o_starts[mymin(Nstarts,(b+1)*p_NT)];

      // output for this thread
      dlong s = b*p_NT+t;
      
      dlong tstart = (s<Nstarts)   ? o_starts[s]  :(-1);
      dlong tend   = (s+1<Nstarts+1) ? o_starts[s+1]:(-1);

      dfloat res = 0;

      // all threads step through all blocks
      for(int bb=bstart;bb<bend;bb+=p_NT){
	//	@barrier("local");
	int loadn = bb + t;
	s_vals[t] = (loadn<N) ? (o_list[loadn].val):(0.0f);
	//	@barrier("local");
	if(tstart!=-1 && tend !=-1){
	  int t0 = mymax(bb,tstart) - bb;
	  int t1 = mymin(bb+p_NT,tend) - bb;
	  for(int l=t0;l<t1;++l){
	    res += s_vals[l]; // likely prone to bank conflicts
	  }
	}
      }
      if(s<Nstarts){
	entry_t ent = o_list[tstart];
	ent.val = res;
	o_compactedList[s] = ent;
      }
    }
  }
}
